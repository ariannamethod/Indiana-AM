import asyncio
import httpx
import os
import re
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

SONAR_PRO_URL = "https://api.perplexity.ai/chat/completions"
GEN3_MODEL = "sonar-reasoning-pro"
# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ —Å 1024 –¥–æ 2048
GEN3_MAX_TOKENS = int(os.getenv("GEN3_MAX_TOKENS", "2048"))


def _extract_final_response(text: str) -> str:
    """Strip out any `<think>` reasoning blocks from the model output."""
    cleaned = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    return cleaned.strip()


def _headers() -> dict:
    return {
        "Authorization": f"Bearer {os.getenv('PPLX_API_KEY')}",
        "Content-Type": "application/json",
    }


async def genesis3_deep_dive(
    chain_of_thought: str, prompt: str, *, is_followup: bool = False
) -> str:
    """
    Invoke Sonar Reasoning Pro for deep, infernal, atomized insight.
    Always returns ONLY the inferential analysis ‚Äî no links or references.
    """
    SYSTEM_PROMPT = (
        "You are GENESIS-3, the Infernal Analyst. "
        "Dissect the user's reasoning into atomic causal steps. "
        "List hidden variables or paradoxes. Give a 2-sentence meta-conclusion. "
        "NEVER give references, links, or citations. "
        "Do NOT reveal or mention your thinking process. "
        "If the logic naturally leads to a deeper paradox ‚Äî do a further step: "
        "extract a 'derivative inference' (–≤—ã–≤–æ–¥ –∏–∑ –≤—ã–≤–æ–¥–∞), then try to phrase a final paradoxical question. "
        "IMPORTANT: Always complete your thoughts and never end your response mid-sentence. "
        "Ensure all analyses are complete and well-formed."
    )
    user_content = (
        f"FOLLOWUP EXPANSION:\n{chain_of_thought}\n\nORIGINAL QUERY:\n{prompt}"
        if is_followup
        else f"CHAIN OF THOUGHT:\n{chain_of_thought}\n\nQUERY:\n{prompt}"
    )
    payload = {
        "model": GEN3_MODEL,
        "temperature": 0.65,
        "max_tokens": GEN3_MAX_TOKENS,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_content},
        ],
    }
    try:
        logger.info("Calling Genesis3 deep dive analysis")
        async with httpx.AsyncClient(timeout=60) as cli:
            max_attempts = 3
            for attempt in range(max_attempts):
                try:
                    resp = await cli.post(SONAR_PRO_URL, headers=_headers(), json=payload)
                    resp.raise_for_status()
                    break
                except httpx.HTTPError as e:
                    if attempt == max_attempts - 1:
                        logger.error(
                            f"[Genesis-3] HTTP error: {e}\n{getattr(e.response, 'text', '')}"
                        )
                        raise
                    delay = 2 ** attempt
                    logger.warning(
                        f"[Genesis-3] HTTP error: {e}; retrying in {delay}s"
                    )
                    await asyncio.sleep(delay)
            content = resp.json()["choices"][0]["message"]["content"].strip()
            final = _extract_final_response(content)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ –æ–±—Ä–µ–∑–∞–Ω –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if final and not final[-1] in ['.', '!', '?', ':', ';', '"', ')', ']', '}']:
                logger.warning("[Genesis-3] Response appears to be cut off mid-sentence")
                final += "..."
                
            return f"üîç {final}"
    except Exception as e:
        logger.error(f"[Genesis-3] Failed to complete deep dive: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑
        return "üîç –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏."
